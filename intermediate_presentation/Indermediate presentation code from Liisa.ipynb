{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning: project\n",
        "# Predicting depression from social media posts\n",
        "## Liisa Jullinen"
      ],
      "metadata": {
        "id": "Mi6cU7o2yC0d"
      },
      "id": "Mi6cU7o2yC0d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the work that our intermediate presentation was based on. The data is from the Reddit Mental Health dataset (https://zenodo.org/records/3941387). We use r/depression and r/fitness (as opposed to the original choice r/personalfinance, that was not as neutral).\n",
        "\n",
        "Other changes regard the selected features. Firstly, we omit df-idf features, because these predict more the subforum subject matter and less the general way people use language. Secondly, we add some new features (that concentrate on depression-specific language use).\n",
        "\n",
        "Training. 2 models are trained and evaluated: logistic regression and SVM."
      ],
      "metadata": {
        "id": "CUu_erPe-Osd"
      },
      "id": "CUu_erPe-Osd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing and setup"
      ],
      "metadata": {
        "id": "gU5eVQeuyayL"
      },
      "id": "gU5eVQeuyayL"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "edcf480e-6b6a-4987-8e04-b6ca08bb94a9",
      "metadata": {
        "id": "edcf480e-6b6a-4987-8e04-b6ca08bb94a9"
      },
      "outputs": [],
      "source": [
        "#!conda install -c conda-forge transformers datasets pytorch scikit-learn -yimport numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from scipy.stats import ttest_ind\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b55c037c-c139-47da-83f4-83ad46eeb9d1",
      "metadata": {
        "id": "b55c037c-c139-47da-83f4-83ad46eeb9d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df7ff864-9e42-4e16-847d-e4c60ffdbc6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-10 11:26:14--  https://zenodo.org/records/3941387/files/fitness_pre_features_tfidf_256.csv?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.52.235, 188.185.48.75, 188.185.43.153, ...\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.52.235|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 54592214 (52M) [text/plain]\n",
            "Saving to: ‘fitness_pre_features_tfidf_256.csv’\n",
            "\n",
            "v                    35%[======>             ]  18.27M   669KB/s    eta 55s    "
          ]
        }
      ],
      "source": [
        "#get data from zenodo\n",
        "!wget -O fitness_pre_features_tfidf_256.csv \"https://zenodo.org/records/3941387/files/fitness_pre_features_tfidf_256.csv?download=1\"\n",
        "!wget -O depression_pre_features_tfidf_256.csv \"https://zenodo.org/records/3941387/files/depression_pre_features_tfidf_256.csv?download=1\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read in data\n",
        "df1 = pd.read_csv(\"depression_pre_features_tfidf_256.csv\", sep=\",\")\n",
        "df2 = pd.read_csv(\"fitness_pre_features_tfidf_256.csv\", sep=\",\")"
      ],
      "metadata": {
        "id": "6HpgSCQps8zN"
      },
      "id": "6HpgSCQps8zN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df1.info()\n",
        "#df1.head(3)\n",
        "list(df1)"
      ],
      "metadata": {
        "id": "UKRKwIUms-0U"
      },
      "id": "UKRKwIUms-0U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " 'liwc_achievement', 'liwc_biological',\n",
        " 'liwc_body', 'liwc_death','liwc_family',\n",
        "'liwc_friends', 'liwc_health',  'liwc_home',\n",
        " 'liwc_humans', 'liwc_ingestion',  'liwc_leisure',\n",
        " 'liwc_money', 'liwc_motion', 'liwc_religion',\n",
        " 'liwc_sexual', 'liwc_work',"
      ],
      "metadata": {
        "id": "_4M4xm09V94-"
      },
      "id": "_4M4xm09V94-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d01b623-b6b0-4aab-9f5f-19fd9c17a49c",
      "metadata": {
        "id": "6d01b623-b6b0-4aab-9f5f-19fd9c17a49c"
      },
      "outputs": [],
      "source": [
        "# add dfs\n",
        "df_ = pd.concat([df1, df2], ignore_index=True)\n",
        "# create label col as 'depressed': 1 depressed, 0 non\n",
        "df_['depressed'] = df_['subreddit'].map({'depression': 1, 'fitness': 0})\n",
        "df_=df_.drop(columns=[\"subreddit\"])\n",
        "# drop tfidf cols (not interested in these)\n",
        "df_ = df_.drop(columns=df_.filter(regex=r\"^tfidf\").columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding a feature that counts absolutist words\n",
        "words_custom = [\"always\", \"never\", \"entire\", \"totally\"]\n",
        "\n",
        "def count_absolutist_words(text, words_custom):\n",
        "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "    return sum(w in words_custom for w in words)\n",
        "\n",
        "df_[\"absolutist\"] = df_[\"post\"].apply(lambda x: count_absolutist_words(x, words_custom))"
      ],
      "metadata": {
        "id": "Hjc3tQtLyg6j"
      },
      "id": "Hjc3tQtLyg6j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seeing if depressed/non-depressed use these word significantly differently\n",
        "\n",
        "df_.head()\n",
        "df_.groupby(\"depressed\")[\"absolutist\"].mean()\n",
        "group1 = df_.loc[df_[\"depressed\"] == 0, \"absolutist\"]\n",
        "group2 = df_.loc[df_[\"depressed\"] == 1, \"absolutist\"]\n",
        "\n",
        "t_stat, p_val = ttest_ind(group1, group2, nan_policy=\"omit\")\n",
        "\n",
        "t_stat, p_val"
      ],
      "metadata": {
        "id": "7IUgrSJh0SBd"
      },
      "id": "7IUgrSJh0SBd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some posts are really long, and thus have very many of these words\n",
        "#df_[\"absolutist\"].unique().max()\n",
        "#df_.loc[df_[\"absolutist\"].idxmax(), \"post\"]\n",
        "#list(df_)"
      ],
      "metadata": {
        "id": "3J0uSxSd9saM"
      },
      "id": "3J0uSxSd9saM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thus I'm calculating a feature showing the % of these words out of all words in a post\n",
        "def absolutist_percentage(text, n_words):\n",
        "    if n_words == 0:\n",
        "        return 0\n",
        "    words = text.lower().split()\n",
        "    count = sum(1 for w in words if w in words_custom)\n",
        "    return (count / n_words) * 100\n",
        "\n",
        "df_[\"absolutist_pct\"] = df_.apply(lambda row: absolutist_percentage(row[\"post\"], row[\"n_words\"]), axis=1)"
      ],
      "metadata": {
        "id": "JyhUYrC4_TT1"
      },
      "id": "JyhUYrC4_TT1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seeing again if groups differ in this stat\n",
        "df_.head()\n",
        "df_.groupby(\"depressed\")[\"absolutist_pct\"].mean()\n",
        "\n",
        "group1 = df_.loc[df_[\"depressed\"] == 0, \"absolutist_pct\"]\n",
        "group2 = df_.loc[df_[\"depressed\"] == 1, \"absolutist_pct\"]\n",
        "\n",
        "t_stat, p_val = ttest_ind(group1, group2, nan_policy=\"omit\")\n",
        "\n",
        "print(t_stat)\n",
        "print(\"{:.12f}\".format(p_val))"
      ],
      "metadata": {
        "id": "NpEH70Ew_13M"
      },
      "id": "NpEH70Ew_13M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffling classes and removing the \"post\" and other features irrelevant for modelling\n",
        "df_ = df_.sample(frac=1, random_state=42).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "lIuapssRBNls"
      },
      "id": "lIuapssRBNls",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_drop = [\n",
        " 'economic_stress_total',\n",
        " 'isolation_total',\n",
        " 'substance_use_total',\n",
        " 'guns_total',\n",
        " 'domestic_stress_total',\n",
        " 'suicidality_total',\n",
        " 'author',\n",
        " 'date',\n",
        " 'post',\n",
        "  'liwc_achievement', 'liwc_biological',\n",
        " 'liwc_body', 'liwc_death','liwc_family',\n",
        "'liwc_friends', 'liwc_health',  'liwc_home',\n",
        " 'liwc_humans', 'liwc_ingestion',  'liwc_leisure',\n",
        " 'liwc_money', 'liwc_motion', 'liwc_religion',\n",
        " 'liwc_sexual', 'liwc_work',]\n",
        "\n",
        "df = df_.drop(columns=cols_drop)\n"
      ],
      "metadata": {
        "id": "eV7FFqvWCAfu"
      },
      "id": "eV7FFqvWCAfu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MODELLING"
      ],
      "metadata": {
        "id": "01Ps9Kpcxkos"
      },
      "id": "01Ps9Kpcxkos"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f94744b7-9a7e-4028-9328-79b523ebb62e",
      "metadata": {
        "id": "f94744b7-9a7e-4028-9328-79b523ebb62e"
      },
      "outputs": [],
      "source": [
        "# train, test, validation\n",
        "train_val, test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['depressed'])\n",
        "train, val = train_test_split(train_val, test_size=0.25, random_state=42, stratify=train_val['depressed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52ac51f8-b5ab-4960-b370-bf77f09b8429",
      "metadata": {
        "id": "52ac51f8-b5ab-4960-b370-bf77f09b8429"
      },
      "outputs": [],
      "source": [
        "print(\"Train:\", len(train), \" Validation:\", len(val), \" Test:\", len(test))\n",
        "print(\"Label distribution:\")\n",
        "print(train['depressed'].value_counts(normalize=True))\n",
        "print(val['depressed'].value_counts(normalize=True))\n",
        "print(test['depressed'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'depressed'\n",
        "\n",
        "X_train = train.drop(columns=[target])\n",
        "y_train = train[target]\n",
        "\n",
        "X_val = val.drop(columns=[target])\n",
        "y_val = val[target]\n",
        "\n",
        "X_test = test.drop(columns=[target])\n",
        "y_test = test[target]"
      ],
      "metadata": {
        "id": "LAGq7XZzDyId"
      },
      "id": "LAGq7XZzDyId",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "ltg1cTfkDyZk"
      },
      "id": "ltg1cTfkDyZk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "clf.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "-5dVODarDycc"
      },
      "id": "-5dVODarDycc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_val_pred_lr = clf.predict(X_val_scaled)\n",
        "\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred_lr))\n",
        "print(classification_report(y_val, y_val_pred_lr))\n"
      ],
      "metadata": {
        "id": "bzniqSUzDyfV"
      },
      "id": "bzniqSUzDyfV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "lSyWiIGyES0e"
      },
      "id": "lSyWiIGyES0e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "feature_names = X_train.columns\n",
        "coefs = clf.coef_[0]\n",
        "\n",
        "\n",
        "coef_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'coefficient': coefs,\n",
        "    'abs_coefficient': np.abs(coefs)\n",
        "})\n",
        "\n",
        "\n",
        "coef_df_sorted = coef_df.sort_values(by='abs_coefficient', ascending=False)\n",
        "\n",
        "print(coef_df_sorted.head(60))\n"
      ],
      "metadata": {
        "id": "Z9xCD3qDEYcN"
      },
      "id": "Z9xCD3qDEYcN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "top_n = 20\n",
        "top_features = coef_df_sorted.head(top_n).copy()\n",
        "\n",
        "\n",
        "top_features['sign'] = top_features['coefficient'].apply(lambda x: 'positive' if x > 0 else 'negative')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(\n",
        "    x='coefficient',\n",
        "    y='feature',\n",
        "    data=top_features,\n",
        "    hue='sign',\n",
        "    dodge=False,\n",
        "    palette={'positive':'red', 'negative':'blue'}\n",
        ")\n",
        "plt.legend([],[], frameon=False)\n",
        "plt.title(f'Top {top_n} Influential Features (Logistic Regression)')\n",
        "plt.xlabel('Coefficient (positive → class 1, negative → class 0)')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wzz4uJDvZQpu"
      },
      "id": "Wzz4uJDvZQpu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeline: scale -> train SVM\n",
        "svm_clf = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVC(kernel='linear', C=1, random_state=42)\n",
        ")\n",
        "\n",
        "\n",
        "svm_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "rdKvA_TWEYwZ"
      },
      "id": "rdKvA_TWEYwZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = svm_clf.predict(X_val)\n",
        "\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(classification_report(y_val, y_val_pred))\n"
      ],
      "metadata": {
        "id": "6o7iCZUdEY0A"
      },
      "id": "6o7iCZUdEY0A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = svm_clf.predict(X_test)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "pLyLabzxEY5F"
      },
      "id": "pLyLabzxEY5F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"Precision\": precision_score(y_true, y_pred),\n",
        "        \"Recall\": recall_score(y_true, y_pred),\n",
        "        \"F1-score\": f1_score(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "\n",
        "metrics_val_lr = get_metrics(y_val, y_val_pred_lr)\n",
        "metrics_test_lr = get_metrics(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "metrics_val_svm = get_metrics(y_val, y_val_pred)\n",
        "metrics_test_svm = get_metrics(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    \"Validation (LR)\": metrics_val_lr,\n",
        "    \"Test (LR)\": metrics_test_lr,\n",
        "    \"Validation (SVM)\": metrics_val_svm,\n",
        "    \"Test (SVM)\": metrics_test_svm\n",
        "})\n",
        "\n",
        "\n",
        "results_df = results_df.round(3)\n",
        "\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "OK470uSIcPsV"
      },
      "id": "OK470uSIcPsV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"Precision\": precision_score(y_true, y_pred),\n",
        "        \"Recall\": recall_score(y_true, y_pred),\n",
        "        \"F1-score\": f1_score(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "\n",
        "results = {\n",
        "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"],\n",
        "    \"Validation (LogisticRegression)\": list(get_metrics(y_val, y_val_pred_lr).values()),\n",
        "    \"Test (LogisticRegression)\": list(get_metrics(y_test, y_test_pred).values()),\n",
        "    \"Validation (SVM)\": list(get_metrics(y_val, y_val_pred).values()),\n",
        "    \"Test (SVM)\": list(get_metrics(y_test, y_test_pred).values())\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.iloc[:, 1:] = results_df.iloc[:, 1:].round(3)\n",
        "print(results_df)\n",
        "\n",
        "# Export to CSV\n",
        "results_df.to_csv(\"model_comparison_results.csv\", index=False)\n",
        "\n",
        "# Export to Excel\n",
        "results_df.to_excel(\"model_comparison_results.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "YBV8MAXHcPv_"
      },
      "id": "YBV8MAXHcPv_",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}